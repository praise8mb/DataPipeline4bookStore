{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BASE_URL = \"http://books.toscrape.com/\"\n",
    "CACHE_FILE = \"books.json\"\n",
    "books = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cache\n",
    "def load_cache():\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        with open(CACHE_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "# Save cache\n",
    "def save_cache(data):\n",
    "    with open(CACHE_FILE, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch a single page and return parsed soup\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Valid, proceeding with scraping:\", url)\n",
    "        return bs(response.text, \"html.parser\")\n",
    "    else:\n",
    "        print(\"Bad request:\", url)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(soup):\n",
    "    for book in soup.select(\".product_pod\"):\n",
    "        title = book.h3.a['title']\n",
    "        price = book.select_one(\".price_color\").text.strip()\n",
    "        stock = book.select_one(\".availability\").text.strip()\n",
    "        rating = book.p['class'][1]\n",
    "\n",
    "        books.append({\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'stock': stock,\n",
    "            'rating': rating\n",
    "        })\n",
    "# Loop through all pages\n",
    "def scrape_all_pages(start_url):\n",
    "    url = start_url\n",
    "    while url:\n",
    "        soup = fetch_page(url)\n",
    "        if soup is None:\n",
    "            break\n",
    "\n",
    "        scrape_page(soup)\n",
    "\n",
    "        next_button = soup.select_one(\"li.next > a\")\n",
    "        if next_button:\n",
    "            url = urljoin(url, next_button['href'])\n",
    "            time.sleep(1)  # Be nice to the server\n",
    "        else:\n",
    "            url = None\n",
    "\n",
    "# Main scraper function\n",
    "def scraper():\n",
    "    scrape_all_pages(BASE_URL)\n",
    "    return books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping website...\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-2.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-3.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-4.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-5.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-6.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-7.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-8.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-9.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-10.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-11.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-12.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-13.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-14.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-15.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-16.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-17.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-18.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-19.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-20.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-21.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-22.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-23.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-24.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-25.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-26.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-27.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-28.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-29.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-30.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-31.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-32.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-33.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-34.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-35.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-36.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-37.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-38.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-39.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-40.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-41.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-42.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-43.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-44.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-45.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-46.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-47.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-48.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-49.html\n",
      "Valid, proceeding with scraping: http://books.toscrape.com/catalogue/page-50.html\n",
      "Data saved to cache.\n"
     ]
    }
   ],
   "source": [
    "# Execution starts here\n",
    "cached_data = load_cache()\n",
    "if cached_data:\n",
    "    print(\"Loaded from cache\")\n",
    "else:\n",
    "    print(\"Scraping website...\")\n",
    "    cached_data = scraper()\n",
    "    if cached_data:\n",
    "        save_cache(cached_data)\n",
    "        print(\"Data saved to cache.\")\n",
    "    else:\n",
    "        print(\"No valid data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   title    price     stock rating\n",
      "0                   A Light in the Attic  Â£51.77  In stock  Three\n",
      "1                     Tipping the Velvet  Â£53.74  In stock    One\n",
      "2                             Soumission  Â£50.10  In stock    One\n",
      "3                          Sharp Objects  Â£47.82  In stock   Four\n",
      "4  Sapiens: A Brief History of Humankind  Â£54.23  In stock   Five\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame and print\n",
    "if cached_data:\n",
    "    df = pd.DataFrame(cached_data)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>stock</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>Â£51.77</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>Â£53.74</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>Â£50.10</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>Â£54.23</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title    price     stock rating\n",
       "0                   A Light in the Attic  Â£51.77  In stock  Three\n",
       "1                     Tipping the Velvet  Â£53.74  In stock    One\n",
       "2                             Soumission  Â£50.10  In stock    One\n",
       "3                          Sharp Objects  Â£47.82  In stock   Four\n",
       "4  Sapiens: A Brief History of Humankind  Â£54.23  In stock   Five"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
